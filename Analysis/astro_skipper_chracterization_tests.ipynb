{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".dataframe th {\n",
    "    font-size: 18px;\n",
    "}\n",
    ".dataframe td {\n",
    "    font-size: 20px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clip\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "import matplotlib.colors\n",
    "sys.path.append('/data/des81.b/data/emarrufo/AstroSkipper_Analysis/astroskip/astroskip/image')\n",
    "sys.path.append('/data/des81.b/data/emarrufo/AstroSkipper_Analysis/full_CCD_characterization/')\n",
    "sys.path.append('/data/des81.b/data/emarrufo/AstroSkipper_Analysis/full_CCD_characterization/ccd-charge-diffusion-master')\n",
    "from skipper_image import *\n",
    "import peak_finding_algorithm \n",
    "import fit_peaks\n",
    "import make_abs_calibration\n",
    "import combined\n",
    "import dratio\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from natsort import natsorted \n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.font_manager as font_manager\n",
    "matplotlib.font_manager._rebuild()\n",
    "import matplotlib.colors\n",
    "import scipy\n",
    "import cp_pipe_functions\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.font_manager as font_manager\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "Here we load the data products for charaterizing the AstroSkipper detectors. Data taking procedure and products definition can be located here https://docs.google.com/document/d/1JaMrdpenERU0nBifb3hPdRZIRxmdC5SqRKWDj2JUhgk/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gain Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_gain(image,plot=True,disp=True):\n",
    "    hdus=4\n",
    "    img = SkipperImage(image)\n",
    "    img_os = img.getImages()\n",
    "    gain=dict()\n",
    "    gain_arr=list()\n",
    "    for i in range(hdus):\n",
    "        clipped_img_os = sigma_clip(img_os[i].flatten(),sigma=3)\n",
    "        _, _, k =peak_finding_algorithm.get_peaks(clipped_img_os, plot=plot)\n",
    "        \n",
    "        gain_arr.append(k)\n",
    "    \n",
    "    gain_arr=np.array(gain_arr)\n",
    "    gain_arr=np.nan_to_num(gain_arr)\n",
    "    m = np.median(gain_arr[gain_arr > 0])\n",
    "    gain_arr[gain_arr == 0] = m\n",
    "    \n",
    "    for i in range(hdus):\n",
    "        gain.update({i:[gain_arr[i]]})\n",
    "\n",
    "    if disp:\n",
    "        df = pd.DataFrame(data=gain)\n",
    "        df.style.set_table_attributes('style=\"font-size: 17px\"')\n",
    "        \n",
    "        title=\"Gain Measurments (ADUs/e-)\"\n",
    "        display(Markdown('<strong>{}'.format(title)))\n",
    "        display(df)\n",
    "    \n",
    "    return np.array(gain_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VSUB (Skipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_vsub_skipping(files,offset=0.4):\n",
    "    hdus=4\n",
    "    gain = get_gain(bckg[-1],plot=False,disp=False)\n",
    "    for f in files:\n",
    "        img = SkipperImage(f)\n",
    "        img_os = np.array(img.getImages())\n",
    "        for hdu in range(hdus):\n",
    "            hdr=fits.open(f)[hdu+1].header\n",
    "            VSUB=hdr['VSUB']\n",
    "            msg = \"VSUB={}\".format(VSUB)\n",
    "            msg_hdu=\"HDU={}\".format(hdu)\n",
    "            display(Markdown('<strong>{}'.format(msg_hdu)))\n",
    "            display(Markdown('<strong>{}'.format(msg)))\n",
    "            img_os_clipped =  sigma_clip(img_os[hdu].flatten(),sigma=3.5)/gain[hdu] + offset \n",
    "            fit_peaks.fit_multi_gaussian(img_os_clipped,-2,7,plot=True)\n",
    "    \n",
    "\n",
    "            \n",
    "#test_vsub_skipping(nsamp_sample_darks_vsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_vr_skipping(files,offset=0.8):\n",
    "    hdus=4\n",
    "    gain = get_gain(bckg[-1],plot=False,disp=False)\n",
    "    for f in files:\n",
    "        img = SkipperImage(f)\n",
    "        img_os = np.array(img.getImages())\n",
    "        for hdu in range(hdus):\n",
    "            hdr=fits.open(f)[hdu+1].header\n",
    "            VR=hdr['VR']\n",
    "            msg = \"VR={}\".format(VR)\n",
    "            msg_hdu=\"HDU={}\".format(hdu)\n",
    "            display(Markdown('<strong>{}'.format(msg_hdu)))\n",
    "            display(Markdown('<strong>{}'.format(msg)))\n",
    "            img_os_clipped =  sigma_clip(img_os[hdu].flatten(),sigma=3.5)/gain[hdu] + offset \n",
    "            fit_peaks.fit_multi_gaussian(img_os_clipped,-2,7,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def single_sample_bias(files, bckg_img,plot=True,disp=True):\n",
    "    hdus=4\n",
    "    median=list()\n",
    "    noise=list()\n",
    "    OSS=3080\n",
    "    gain = get_gain(bckg[-1],plot=False,disp=False)\n",
    "    \n",
    "    for hdu in range(hdus):\n",
    "        for file in files:\n",
    "            img=fits.open(file)\n",
    "            full_img = sigma_clip(img[hdu].data[:,:].flatten(),maxiters=None) / gain[hdu]\n",
    "            OS=sigma_clip(img[hdu].data[:,OSS:].flatten(),maxiters=None) / gain[hdu]\n",
    "            median.append(np.median(full_img))\n",
    "            noise.append(np.std(OS))   \n",
    "    if plot:\n",
    "        font = FontProperties()\n",
    "        #font.set_name('Cambria Math')\n",
    "        #plt.rcParams[\"font.family\"] = \"Cambria Math\"\n",
    "        median=np.array(median).reshape(hdus,len(files))\n",
    "        noise=np.array(noise).reshape(hdus,len(files))\n",
    "        fig1, ax1 = plt.subplots(figsize=(8, 5))\n",
    "        for i in range(hdus):\n",
    "            plt.scatter(np.arange(0,len(files),1),median[i],s=50,label=\"HDU={}\".format(i))\n",
    "        \n",
    "        plt.grid()\n",
    "        ax1.set_ylabel('Signal Median, $\\mu_{S}$ (e-/pix)', fontsize=30)\n",
    "        ax1.set_xlabel('Image Number',fontsize=30)\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=25)\n",
    "        plt.legend(loc='best',fontsize=15)\n",
    "        plt.show()\n",
    "        \n",
    "        fig2, ax2 = plt.subplots(figsize=(8, 5))\n",
    "        for i in range(hdus):\n",
    "            plt.scatter(np.arange(0,len(files),1),noise[i],s=50, marker=\"x\",label=\"HDU={}\".format(i))\n",
    "        \n",
    "        plt.grid()\n",
    "        ax2.set_ylabel('Signal Noise, $\\sigma_{S}$ (e- rms/pix)', fontsize=30)\n",
    "        ax2.set_xlabel('Image Number',fontsize=30)\n",
    "        ax2.tick_params(axis='both', which='major', labelsize=25)\n",
    "        plt.legend(loc='best',fontsize=15)\n",
    "        plt.show()\n",
    "    \n",
    "    if disp:\n",
    "        noise=np.array(noise).reshape(hdus,len(files))\n",
    "        avg_noise=np.mean(noise,axis=1)\n",
    "        noise_dict=dict()\n",
    "        \n",
    "        for i in range(hdus):\n",
    "            noise_dict.update({i:[avg_noise[i]]})\n",
    "        \n",
    "        df = pd.DataFrame(data=noise_dict)\n",
    "        df.style.set_table_attributes('style=\"font-size: 17px\"')\n",
    "        title = \"Average Noise/HDU (e- rms/pix)\"\n",
    "        display(Markdown('<strong>{}'.format(title)))\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def background(file,bckg_img,offset=0,plot=False):\n",
    "    hdus=4\n",
    "    img = SkipperImage(file)\n",
    "    img_os = img.getOverscans()\n",
    "    img_active = img.getImages()\n",
    "    gain = get_gain(bckg_img,plot=False,disp=False)\n",
    "    median=list()\n",
    "    for i in range(hdus):\n",
    "        clipped_img_active = sigma_clip(img_active[i].flatten(),sigma=3.5)/gain[i] + offset\n",
    "        median.append(np.median(clipped_img_active))\n",
    "        if plot:\n",
    "            fit_peaks.fit_multi_gaussian(clipped_img,-1,5,plot=False)\n",
    "    \n",
    "    return np.array(median)\n",
    "\n",
    "def sp_charge(file,bckg_img,offset=0.8,plot=False):\n",
    "    hdus=4\n",
    "    img = SkipperImage(file)\n",
    "    img_os = img.getOverscans()\n",
    "    img_active = img.getImages()\n",
    "    gain = get_gain(bckg_img,plot=False,disp=False)\n",
    "    spurios=dict()\n",
    "    b=background(bckg_img,bckg_img,offset=0,plot=False)\n",
    "    b=b[b >= 0]\n",
    "    b_average=np.mean(b)\n",
    "    for i in range(hdus):\n",
    "        clipped_img_active = sigma_clip(img_active[i].flatten(),sigma=3.5)/gain[i] + offset\n",
    "        spurios.update({i:[np.median(clipped_img_active) - b_average]})\n",
    "\n",
    "        \n",
    "        if plot:\n",
    "            fit_peaks.fit_multi_gaussian(clipped_img_active,-1,8,plot=plot)\n",
    "    \n",
    "    df = pd.DataFrame(data=spurios)\n",
    "    df.style.set_table_attributes('style=\"font-size: 17px\"')\n",
    "    title = \"Spurious  Charge/HDU (e- rms/pix)\"\n",
    "    display(Markdown('<strong>{}'.format(title)))\n",
    "    display(df)\n",
    "    \n",
    "#sp_charge(nsamp_biases_sp [-2],bckg[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dark_current(files,bckg_img):\n",
    "    hdus=4\n",
    "    exp_time=400\n",
    "    out_combined_dark=\"combined_dark.fits\"\n",
    "    combined.make_combined_img(files,out_combined_dark)\n",
    "    combined_dark = fits.open(out_combined_dark)\n",
    "    median=list()\n",
    "    gain= get_gain(bckg_img,plot=False,disp=False)\n",
    "    dc=dict()\n",
    "\n",
    "    for hdu in range(hdus):\n",
    "        data_dark = sigma_clip(combined_dark[hdu].data[:,:].flatten(),maxiters=None,sigma=3)\n",
    "        dc.update({hdu:[np.median(data_dark)/gain[hdu]/exp_time]})\n",
    "    \n",
    "    df = pd.DataFrame(data=dc)\n",
    "    df.style.set_table_attributes('style=\"font-size: 17px\"')\n",
    "    title = \"Dark Current (e-/pix/sec)\"\n",
    "    display(Markdown('<strong>{}'.format(title)))\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bad_pixels_dark(files,plot=False,plot_mask=True):\n",
    "    out_combined_dark=\"combined_dark.fits\"\n",
    "    combined.make_combined_img(files,out_combined_dark)\n",
    "    amps=4\n",
    "    image = fits.open(out_combined_dark)\n",
    "    #image = fits.open(files[0])\n",
    "    img_shape=image[1].shape\n",
    "    bad_pix_percent=dict()\n",
    "    \n",
    "    \n",
    "    msg=\"Darks(bright pixels)\"\n",
    "    display(Markdown('<strong>{}'.format(msg)))\n",
    "    \n",
    "    if plot:\n",
    "        for i in range(amps):\n",
    "            img=(image[i].data.flatten())\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.hist(img,bins=np.linspace(np.min(img),np.max(img),150),\n",
    "                     histtype='step',density=False,color='orange')\n",
    "            plt.yscale('log')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "    \n",
    "    for i in range(amps):\n",
    "        masked_img = sigma_clip(image[i].data.flatten(),masked=True,sigma=4)\n",
    "        mask=masked_img.mask.reshape(img_shape)\n",
    "        total_pixels = len(masked_img)\n",
    "        num_bad_pixels =len(np.where(masked_img.mask==True)[0])\n",
    "        percent_bad =  num_bad_pixels/total_pixels\n",
    "        bad_pix_percent.update({i:[percent_bad]})\n",
    "\n",
    "        \n",
    "        if plot_mask:\n",
    "            cmap = matplotlib.colors.ListedColormap(['black', 'white'])\n",
    "            plt.figure(figsize=(15,15))\n",
    "            plt.imshow(mask, cmap=cmap)\n",
    "            #plt.colorbar()\n",
    "            plt.show()\n",
    "        \n",
    "    df = pd.DataFrame(data=bad_pix_percent)\n",
    "    df.style.set_table_attributes('style=\"font-size: 17px\"')\n",
    "    title = \"Percentage of bad pixels/HDU\"\n",
    "    display(Markdown('<strong>{}'.format(title)))\n",
    "    display(df)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bad_pixels_flat(files,plot_mask=True):\n",
    "    out_combined_flat=\"combined_flat.fits\"\n",
    "    combined.make_combined_img(files,out_combined_flat)\n",
    "    amps=4\n",
    "    OSS=3079\n",
    "    image = fits.open(out_combined_flat)\n",
    "    img_shape=image[1].shape\n",
    "    bad_pix_percent=dict()\n",
    "    \n",
    "    msg=\"Flats(dead pixels)\"\n",
    "    display(Markdown('<strong>{}'.format(msg)))\n",
    "    \n",
    "    for i in range(amps):\n",
    "        \n",
    "        masked_img = sigma_clip(image[i].data.flatten(),masked=True,sigma=3.5)\n",
    "        mask=masked_img.mask.reshape(img_shape)\n",
    "        total_pixels =len(masked_img)\n",
    "        num_bad_pixels =len(np.where(masked_img.mask==True)[0])\n",
    "        percent_bad = num_bad_pixels/total_pixels\n",
    "        bad_pix_percent.update({i:[percent_bad]})\n",
    "\n",
    "        \n",
    "        if plot_mask:\n",
    "            cmap = matplotlib.colors.ListedColormap(['black', 'white'])\n",
    "            plt.figure(figsize=(15,15))\n",
    "            plt.imshow(mask, cmap=cmap)\n",
    "            #plt.colorbar(orientation=\"horizontal\", pad=0.05)\n",
    "            plt.show()      \n",
    "            \n",
    "    df = pd.DataFrame(data=bad_pix_percent)\n",
    "    title= \"Percentage of bad pixels/HDU\"\n",
    "    display(Markdown('<strong>{}'.format(title)))\n",
    "    display(df)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Linearity \n",
    "def linearity(files,time_idx,plot=True):\n",
    "    f_line = lambda x, *p: p[0] * x + p[1]\n",
    "    def nonlinear(params,signal,time):\n",
    "        model = f_line(np.array(time),*params)\n",
    "        deviation = signal - model \n",
    "        non_linearity = (np.max(deviation) + np.min(deviation)) / np.max(signal)\n",
    "        return  np.abs(non_linearity)\n",
    "    \n",
    "    hdus=4\n",
    "    OSS=3079\n",
    "    signal_mean=list()\n",
    "    time=list()\n",
    "    \n",
    "    for f in files:\n",
    "        time.append(float(basename(f).split('_')[time_idx]))\n",
    "        \n",
    "    for hdu in range(hdus):\n",
    "        for f in files:\n",
    "            img=fits.open(f)\n",
    "            full_img = sigma_clip(img[hdu].data[:,:OSS].flatten(),maxiters=None)\n",
    "            signal_mean.append(np.median(full_img))\n",
    "    \n",
    "    signal_mean = np.array(signal_mean).reshape(hdus,len(files))\n",
    "    signal_mean = np.nan_to_num(signal_mean)\n",
    "    \n",
    "    if plot:\n",
    "        font = FontProperties()\n",
    "        font.set_name('Cambria Math')\n",
    "        for i in range(hdus):\n",
    "            params,cov = scipy.optimize.curve_fit(f_line, xdata=np.array(time), ydata=signal_mean[i], p0=(20000,40))\n",
    "            y_fit = f_line(np.array(time),*params)\n",
    "            nl=nonlinear(params,signal_mean[i],time)\n",
    "            fig1, ax1 = plt.subplots(figsize=(8, 8))\n",
    "            plt.scatter(time,signal_mean[i],s=100,marker = \"x\",label=\"HDU={}\".format(i))\n",
    "            plt.plot(time, y_fit, '--', color='red',linewidth=3)\n",
    "            plt.grid()\n",
    "            plt.title(\"Non-linearity = {:.3}\".format(nl),fontsize=30)\n",
    "            ax1.set_ylabel('Signal Mean, $\\mu_{S}$ (ADU)', fontsize=35)\n",
    "            ax1.set_xlabel('Exposure Time(s)',fontsize=35)\n",
    "            ax1.tick_params(axis='both', which='major', labelsize=30)\n",
    "            plt.legend(loc='best',fontsize=20)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary with path to each image where trial \n",
    "def FileDict(files):\n",
    "    fileArray=dict()\n",
    "    for f in files:\n",
    "        time=float(basename(f).split('_')[10])\n",
    "        trial=int(basename(f).split('_')[13])\n",
    "        if(not (time in fileArray.keys())):\n",
    "            fileArray[time]=dict()\n",
    "        fileArray[time][trial]=f\n",
    "    return fileArray\n",
    "\n",
    "# gets the exposure times \n",
    "def getTimes(f):\n",
    "    timesAsc=np.sort(list(FileDict(f).keys()))\n",
    "    return timesAsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ptc(f,sigma=3.5):\n",
    "    hdus=4\n",
    "    OSS=3100\n",
    "    skipRow=5\n",
    "    skipCol=2000\n",
    "    noiseStds=np.zeros(shape=(hdus,len(getTimes(f))))\n",
    "    mu=np.zeros(shape=(hdus,len(getTimes(f))))\n",
    "    signalDiffVar=np.zeros(shape=(hdus,len(getTimes(f))))\n",
    "    gain=get_gain(bckg[-1],plot=False,disp=False)\n",
    "\n",
    "    for hdu in range(hdus):\n",
    "        for i in range(0,len(getTimes(f))):\n",
    "            timeFiles=FileDict(f)[getTimes(f)[i]]\n",
    "            trial1=timeFiles[1]\n",
    "            trial2=timeFiles[2]\n",
    "            full_image=fits.open(trial2)\n",
    "            OS=sigma_clip(full_image[hdu].data[skipRow:,OSS:].flatten(),maxiters=None,sigma=sigma)\n",
    "            \n",
    "            img1=fits.open(trial1)\n",
    "            img1=sigma_clip(img1[hdu].data[skipRow:,skipCol:OSS].flatten(),maxiters=None,sigma=sigma)\n",
    "            \n",
    "            img2=fits.open(trial2)\n",
    "            img2=sigma_clip(img2[hdu].data[skipRow:,skipCol:OSS].flatten(),maxiters=None,sigma=sigma)\n",
    "            \n",
    "            mu_1 = np.ma.mean(img1)\n",
    "            mu_2 =np.ma.mean(img2)\n",
    "            mu[hdu][i]=(mu_1 + mu_2)/2.0\n",
    "            img1=img1-np.ma.median(img1)\n",
    "            img2=img2-np.ma.median(img2)\n",
    "            \n",
    "            noiseStds[hdu][i]=np.ma.std(sigma_clip(OS.flatten(),maxiters=None,sigma=sigma))\n",
    "            \n",
    "            imgDiff = (mu_2*img1 - mu_1*img2)/mu[hdu][i]\n",
    "            varDiff = np.ma.var(imgDiff)/2\n",
    "            varFactor = cp_pipe_functions.sigmaClipCorrection(sigma)**2\n",
    "            varDiff*= varFactor\n",
    "            signalDiffVar[hdu][i] = varDiff\n",
    "    avg_noise = np.median(noiseStds,axis=1)\n",
    "    for hdu in range(hdus):\n",
    "       \n",
    "        initialParams = [-1e-6,1./gain[hdu], avg_noise[hdu]**2] \n",
    "        polyFit, polyFitErr, chiSq, weightsY = cp_pipe_functions.irlsFit(initialParams, mu[hdu][7:-23],\n",
    "                                                                         signalDiffVar[hdu][7:-23],\n",
    "                                                                         cp_pipe_functions.funcAstier)\n",
    "        x_fit = np.arange(np.min(mu[hdu]),np.max(mu[hdu]),100)\n",
    "        y_fit =  cp_pipe_functions.funcAstier(polyFit, x_fit)\n",
    "        gain_hdu = 1/polyFit[1]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        max_mean=np.max(mu[hdu])\n",
    "        \n",
    "        textstr = '\\n'.join((\n",
    "            r'$FW=%.0f$ e-' % (max_mean/gain_hdu, ),\n",
    "            r'$a_{00}=%.2e$' % (polyFit[0], ),\n",
    "            r'$gain=%.2f$ ADU/e-' % (gain_hdu, ),\n",
    "            r'$\\sigma=%.2f$ e- rms/pix' % (avg_noise[hdu]/gain_hdu , )))\n",
    "        \n",
    "        props = dict(boxstyle='square', facecolor='white', alpha=0.2)\n",
    "        ax.text(0.05, 0.75, textstr, transform=ax.transAxes, fontsize=20,\n",
    "                verticalalignment='top', bbox=props)\n",
    "\n",
    "        plt.scatter(mu[hdu],signalDiffVar[hdu], s=100, marker=\"X\", label='Signal')\n",
    "        plt.plot(x_fit,y_fit,'--r',label=\"Model Fit\")\n",
    "        plt.scatter(max_mean,cp_pipe_functions.funcAstier(polyFit,max_mean), marker=\"*\", label = \"Full Well\",s=700)\n",
    "        ax.set_xlabel('Signal Mean, $\\mu_{S}$ (ADU)', fontsize=35)\n",
    "        ax.set_ylabel('Signal Variance, $\\sigma^{2}_{S}$ (ADU)',fontsize=35)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "        plt.legend(loc='best',fontsize=20)\n",
    "        plt.grid()\n",
    "        plt.yscale('log')\n",
    "        plt.xscale('log')\n",
    "        plt.show()\n",
    "    \n",
    "#ptc(ptc_files,sigma=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cti(files):\n",
    "    hdus=4\n",
    "    nTransfers=3200\n",
    "    row_min=10\n",
    "    row_max=50\n",
    "    first_OS=3080\n",
    "    OSS=3079\n",
    "    CTI=np.zeros(shape=(hdus,len(getTimes(files))))\n",
    "    mu=np.zeros(shape=(hdus,len(getTimes(files))))\n",
    "    CTI_dict=dict()\n",
    "    gain=get_gain(bckg[-1],plot=False,disp=False)\n",
    "    skipRow=5\n",
    "    skipCol=2000\n",
    "    marker =[\"p\",\"v\",\"*\",'X']\n",
    "    \n",
    "    for hdu in range(hdus):\n",
    "        for i in range(0,len(getTimes(files))):\n",
    "            timeFiles=FileDict(files)[getTimes(files)[i]]\n",
    "            trial1=timeFiles[1]\n",
    "            trial2=timeFiles[2]\n",
    "            \n",
    "            img1=fits.open(trial1)\n",
    "            img2=fits.open(trial2)            \n",
    "            \n",
    "            dc_1 = np.mean((img1[hdu].data[row_min:row_max,first_OS]))/gain[hdu]\n",
    "            dc_2 = np.mean((img2[hdu].data[row_min:row_max,first_OS]))/gain[hdu]\n",
    "            \n",
    "            \n",
    "            img1_data=sigma_clip(img1[hdu].data[skipRow:,skipCol:OSS].flatten(),maxiters=None)\n",
    "            img2_data=sigma_clip(img2[hdu].data[skipRow:,skipCol:OSS].flatten(),maxiters=None)\n",
    "            \n",
    "            mu_1 = np.ma.mean(img1_data)\n",
    "            mu_2 =np.ma.mean(img2_data)\n",
    "            mu[hdu][i]=(mu_1 + mu_2)/2.0\n",
    "            \n",
    "            lc_1= np.mean((img1[hdu].data[row_min:row_max,OSS]))/gain[hdu]\n",
    "            lc_2= np.mean((img2[hdu].data[row_min:row_max,OSS]))/gain[hdu]\n",
    "\n",
    "        \n",
    "            CTI_1 = np.abs(dc_1/(lc_1*nTransfers))\n",
    "            CTI_2 = np.abs(dc_2/(lc_2*nTransfers))\n",
    "            CTI[hdu][i] = (CTI_1+CTI_2)/2\n",
    "                        \n",
    "    CTI_median = np.median(CTI,axis=1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    for hdu in range(hdus):\n",
    "        CTI_dict.update({hdu:[CTI_median[hdu]]})\n",
    "        plt.scatter(mu[hdu]/gain[hdu],CTI[hdu],s=150,alpha=1 ,label = \"HDU={}\".format(hdu), marker=marker[hdu])\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.xlabel(r\"$\\rm Signal (e^{-}/pix)$\",fontsize=40)\n",
    "    plt.ylabel(\"CTI\",fontsize=40)\n",
    "    plt.legend(loc='best',fontsize=20)\n",
    "    plt.ylim(-1e-9,1e-7)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame(data=CTI_dict)\n",
    "    title=\"Median CTI/HDU\"\n",
    "    display(Markdown('<strong>{}'.format(title)))\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_abs_qe(proc_qe_files,raw_qe_files,exp_time=4.2):\n",
    "    hdus=4\n",
    "    gain=get_gain(bckg[-1],plot=False,disp=False)\n",
    "    h=6.625e-34\n",
    "    c=2.998e8\n",
    "    OSS=3100\n",
    "    row_min=10\n",
    "    row_max=100\n",
    "    col_min=1000\n",
    "    \n",
    "    \"\"\"Get QE data from a file list.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    files : file list\n",
    "    gain  : detector gain [ADU/e-]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : summary data from images\n",
    "    \"\"\"\n",
    "    abs_QE = np.zeros(shape=(hdus,len(proc_qe_files)))\n",
    "    waves=list()\n",
    "    power=list()\n",
    "    \n",
    "    for fz in raw_qe_files:\n",
    "        hdr=fits.open(fz)[0].header\n",
    "        waves.append(hdr['WAVE'])\n",
    "        power.append(hdr['POWER'])\n",
    "    \n",
    "    power =np.array(power)*make_abs_calibration.get_calibration()\n",
    "    \n",
    "    for hdu in range(hdus):\n",
    "        for i,f in enumerate(proc_qe_files):\n",
    "            img=fits.open(f)\n",
    "            os=sigma_clip(img[hdu].data[:,OSS:].flatten(),maxiters=None)\n",
    "            act=sigma_clip(img[hdu].data[row_min:row_max,col_min:OSS].flatten(),maxiters=None)\n",
    "            \n",
    "            # Compute absolute QE\n",
    "            \n",
    "            mean_OS = np.mean(os)\n",
    "            mean_ACT = np.mean(act)\n",
    "            mean = mean_ACT-mean_OS\n",
    "            \n",
    "            # Convert from ADUs to elelctrons \n",
    "            mean_electron=mean/gain[hdu]\n",
    "            abs_qe = mean_electron * ((h*c)/(power[i]*exp_time*(waves[i])/(1e9)))\n",
    "            abs_QE[hdu][i]=abs_qe\n",
    "    \n",
    "    h,q,w=np.loadtxt('qe.txt',usecols=(0,1,2),unpack=True)\n",
    "    flaugher = pd.read_csv('decam_qe_flaugher.csv',comment='#')\n",
    "    font = FontProperties(size= 35)\n",
    "    font.set_style('normal')\n",
    "\n",
    "    Astro_5_qe = np.load('Astro_5_ABS_QE.npy')\n",
    "\n",
    "    \n",
    "    for hdu in range(hdus):\n",
    "        fig, ax = plt.subplots(figsize=(13, 8))\n",
    "        plt.plot(waves,abs_QE[hdu],'o',alpha=0.8,markersize=10,\n",
    "                 color='green',label=\"AstroSkipper 8\",\n",
    "                 zorder=1,marker=\"X\")\n",
    "        plt.xlim(390,1200)\n",
    "        plt.grid()\n",
    "        ax.set_xlabel('Wavelength (nm)',fontproperties=font)\n",
    "        ax.set_ylabel('Absolute QE',fontproperties=font)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "        plt.legend(fontsize=20)\n",
    "        plt.show()\n",
    "calculate_abs_qe(qe_files,qe_files_fz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def diffusion(files):\n",
    "    '''\n",
    "    Code from David Lawrence, Paul O’Connor, et al.,  \n",
    "    “Model-independent Characterization of Charge Diffusion in Thick Fully Depleted CCDs”\n",
    "    '''\n",
    "    marker =[\"p\",\"v\",\"*\",'X']\n",
    "    psf_sigma=list()\n",
    "    vsub=[30,40,50,60,70]\n",
    "    hdus=4\n",
    "    gain=get_gain(bckg[-1],plot=False,disp=False)\n",
    "    for hdu in range(hdus):\n",
    "        for f in files:\n",
    "            img_xray= fits.open(f)\n",
    "            img_xray=img_xray[hdu].data / gain[hdu]\n",
    "            psf_sigma.append(dratio.analyze(img_xray[10:,1000:])[0])\n",
    "\n",
    "    psf_sigma = np.array(psf_sigma).reshape(hdus,len(vsub),len(vsub))\n",
    "    psf_sigma_mean = np.mean(psf_sigma,axis=2)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8)) \n",
    "    for hdu in range(hdus):\n",
    "        plt.scatter(vsub,psf_sigma_mean[hdu],s=120,alpha=1 ,label = \"HDU={}\".format(hdu), marker=marker[hdu])\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "    plt.xlabel(\"VSUB\",fontsize=40)\n",
    "    plt.ylabel(\"PSF size (pixels)\",fontsize=40)\n",
    "    plt.legend(loc='best',fontsize=20)\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
