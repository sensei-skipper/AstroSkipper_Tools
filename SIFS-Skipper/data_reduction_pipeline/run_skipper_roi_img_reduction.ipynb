{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys,os\n",
    "import shutil\n",
    "from os.path import basename\n",
    "from glob import glob\n",
    "import logging \n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "\n",
    "# Image correction algorithm \n",
    "#sys.path.append('add path to class directory if different')\n",
    "from skipper_roi_img_reduction import *\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.NOTSET)\n",
    "log = logging.getLogger(\"data_reduction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bias_correction(raw_file_path, out_file_path, ROI=True, \n",
    "                          correction_type='SP', single_sample=False, \n",
    "                          gain_correction=False):\n",
    "    \"\"\"\n",
    "    Apply overscan and optional gain corrections to a raw Skipper image, then save the result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_file_path : str\n",
    "        Path to the raw FITS file to be processed.\n",
    "    out_file_path : str\n",
    "        Path where the corrected FITS file will be saved.\n",
    "    ROI : bool, optional\n",
    "        Whether to interpret and apply ROI definitions from the FITS header. \n",
    "        If True, the function processes ROI-specific overscan corrections. \n",
    "        Defaults to True.\n",
    "    correction_type : str, optional\n",
    "        The overscan correction method. Common options include:\n",
    "          - 'S': Serial overscan correction only.\n",
    "          - 'P': Parallel overscan correction only.\n",
    "          - 'SP': Both serial and parallel overscan correction.\n",
    "        Defaults to 'SP'.\n",
    "    single_sample : bool, optional\n",
    "        If True, process the image as a single-sample calibration product. \n",
    "        This may restrict the available overscan corrections (e.g., only \n",
    "        serial). Defaults to False.\n",
    "    gain_correction : bool, optional\n",
    "        If True, apply gain correction using a gain file loaded by the \n",
    "        `SkipperImageROI` class (either a default file or user-provided). \n",
    "        Defaults to False.\n",
    "    \"\"\"\n",
    "    img = SkipperImageROI(filename=raw_file_path,\n",
    "                          overscan_correction_type=correction_type,\n",
    "                          manual_input_slices=False,\n",
    "                          correction_method=\"CUBIC_SPLINE\",\n",
    "                          ROI=ROI,\n",
    "                          calibration_single_sample=single_sample,\n",
    "                          gain_correction=gain_correction)\n",
    "    \n",
    "    img.save(out_file_path)\n",
    "\n",
    "\n",
    "def create_combined_product(fits_dir, out_file_path, norm=True):\n",
    "    \"\"\"\n",
    "    Create a median-combined (and optionally row-normalized) FITS product from 'proc' files.\n",
    "\n",
    "    This function searches `fits_dir` for all FITS files containing 'proc' in their \n",
    "    filenames, then median-combines the data from each amplifier HDU across these files. \n",
    "    It also offers an option to normalize each row by its median value before writing \n",
    "    the final combined data to `out_file_path`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_dir : str\n",
    "        Path to the directory containing the 'proc' FITS files to be combined.\n",
    "    out_file_path : str\n",
    "        Path where the resulting combined FITS product will be saved.\n",
    "    norm : bool, optional\n",
    "        If True, each row in the combined product is divided by its median value,\n",
    "        effectively performing a row-by-row normalization. Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Returns 0 if no files with 'proc' in their names were found in `fits_dir`.\n",
    "        Otherwise, no value is returned (None).\n",
    "    \"\"\"\n",
    "    new_hdul = fits.HDUList()\n",
    "    fits_files = [f for f in os.listdir(fits_dir) if 'proc' in f.lower()]\n",
    "\n",
    "    if len(fits_files) == 0:\n",
    "        log.warning(\"No 'proc' files found in the directory\")\n",
    "        return 0\n",
    "    \n",
    "    first_file = fits.open(os.path.join(fits_dir, fits_files[0]))\n",
    "    num_hdus = len(first_file) \n",
    "    num_rows, num_cols = first_file[1].data.shape  \n",
    "    \n",
    "    # Create a new HDU list starting with the primary HDU from the first file\n",
    "    new_hdul.append(fits.PrimaryHDU(header=first_file[0].header))\n",
    "   \n",
    "    # Initialize an array to hold all images for median combination\n",
    "    all_images = np.zeros((len(fits_files), num_hdus - 1, num_rows, num_cols))\n",
    "    \n",
    "    # Load data from each 'proc' file\n",
    "    for i, fits_file in enumerate(fits_files):\n",
    "        hdul = fits.open(os.path.join(fits_dir, fits_file))\n",
    "        for j in range(1, num_hdus):\n",
    "            all_images[i, j - 1] = hdul[j].data\n",
    "        hdul.close()\n",
    "    \n",
    "    # Compute the median across all files\n",
    "    combined_product = np.median(all_images, axis=0)\n",
    "    \n",
    "    # Optional row-wise normalization\n",
    "    if norm:\n",
    "        for i in range(combined_product.shape[0]):\n",
    "            row_medians = np.median(combined_product[i], axis=1)\n",
    "            combined_product[i] = combined_product[i] / row_medians[:, np.newaxis]\n",
    "\n",
    "    # Create new HDUs for each amplifier and update headers\n",
    "    for i in range(num_hdus - 1):\n",
    "        header = first_file[i + 1].header\n",
    "        new_hdu = fits.PrimaryHDU(combined_product[i])\n",
    "        new_hdu.header.update(header)\n",
    "        new_hdul.append(new_hdu)\n",
    "    \n",
    "    new_hdul.writeto(out_file_path, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_classification(dir_path):\n",
    "    \"\"\"\n",
    "    Classify and organize FITS files based on their header information.\n",
    "\n",
    "    This function:\n",
    "      1. Identifies all `.fits` files in the specified directory.\n",
    "      2. Reads each file's header to determine the \"OBSTYPE\" keyword,\n",
    "         creating a corresponding subdirectory if it does not already exist.\n",
    "      3. Copies the original `.fits` file into that subdirectory.\n",
    "      4. Further checks each file's \"OBJECT\" keyword:\n",
    "         - If it contains \"focus\", the file is moved to a \"FOCUS\" subdirectory.\n",
    "         - Otherwise, a subdirectory named after the `OBJECT` keyword is created,\n",
    "           and the file is moved there.\n",
    "      5. Returns a list of newly created subdirectories (those intended to \n",
    "         be corrected later in the data-reduction pipeline).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_path : str\n",
    "        The path to the directory containing the `.fits` files \n",
    "        that need to be classified.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        A list of directories that were created for specific objects\n",
    "        and are expected to hold files for further processing.\n",
    "    \"\"\"\n",
    "    all_files = [file for file in os.listdir(dir_path) if file.endswith(\".fits\")]\n",
    "    path_to_files = [os.path.join(dir_path, file) for file in all_files]\n",
    "    header_index_info = 0\n",
    "    images_to_correct_dirs = list()\n",
    "\n",
    "    for file in path_to_files:\n",
    "        fits_hdu_list = fits.open(file)\n",
    "        type_name = fits_hdu_list[header_index_info].header.get(\"OBSTYPE\", \"UNKNOWN\")\n",
    "        type_dir = os.path.join(dir_path, type_name)\n",
    "\n",
    "        if not os.path.exists(type_dir):\n",
    "            os.makedirs(type_dir)\n",
    "\n",
    "        new_file_path = os.path.join(type_dir, os.path.basename(file))\n",
    "        shutil.copy2(file, new_file_path)\n",
    "\n",
    "    # Check for focusing files (we do not need to correct these).\n",
    "    for type_name in os.listdir(dir_path):\n",
    "        type_dir = os.path.join(dir_path, type_name)\n",
    "\n",
    "        if os.path.isdir(type_dir):\n",
    "            focus_dir = os.path.join(type_dir, \"FOCUS\")\n",
    "            for file in os.listdir(type_dir):\n",
    "                file_path = os.path.join(type_dir, file)\n",
    "                if file.endswith(\".fits\"):\n",
    "                    fits_hdu_list = fits.open(file_path)\n",
    "                    object_name = fits_hdu_list[header_index_info].header.get(\"OBJECT\", \"UNKNOWN\").lower()\n",
    "\n",
    "                    if \"focus\" in object_name:\n",
    "                        if not os.path.exists(focus_dir):\n",
    "                            os.makedirs(focus_dir)\n",
    "\n",
    "                        new_focus_path = os.path.join(focus_dir, os.path.basename(file))\n",
    "                        shutil.move(file_path, new_focus_path)\n",
    "\n",
    "    for type_name in os.listdir(dir_path):\n",
    "        type_dir = os.path.join(dir_path, type_name)\n",
    "\n",
    "        if os.path.isdir(type_dir):\n",
    "            for file in os.listdir(type_dir):\n",
    "                file_path = os.path.join(type_dir, file)\n",
    "\n",
    "                if file.endswith(\".fits\"):\n",
    "                    fits_hdu_list = fits.open(file_path)\n",
    "                    object_name = fits_hdu_list[header_index_info].header.get(\"OBJECT\", \"UNKNOWN\")\n",
    "\n",
    "                    # Create a directory for each object name\n",
    "                    object_dir = os.path.join(type_dir, object_name)\n",
    "                    if not os.path.exists(object_dir):\n",
    "                        os.makedirs(object_dir)\n",
    "                        images_to_correct_dirs.append(object_dir)\n",
    "\n",
    "                    new_object_path = os.path.join(object_dir, os.path.basename(file))\n",
    "                    shutil.move(file_path, new_object_path)\n",
    "\n",
    "    return images_to_correct_dirs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_reduction(dir_path, flat_filed=True):\n",
    "    \"\"\"\n",
    "    Perform a multi-step image reduction process on SIFS-Skipper CCD data.\n",
    "\n",
    "    This function executes an automated workflow to:\n",
    "\n",
    "    1. Classify input FITS files based on their headers (using `file_classification`).\n",
    "    2. Apply bias subtraction (using `apply_bias_correction`) to produce 'proc_' files.\n",
    "    3. Combine and optionally normalize milky-flatfield and bias data \n",
    "       (using `create_combined_product`).\n",
    "    4. Apply flatfield corrections (optional) for object images if a \n",
    "       combined milky-flatfield product is available.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_path : str\n",
    "        Path to the directory containing raw or newly sorted FITS files. \n",
    "        Subdirectories will be created automatically for each OBSTYPE \n",
    "        and OBJECT found in the headers.\n",
    "    flat_filed : bool, optional\n",
    "        If True, the function attempts to create and use combined \n",
    "        milky-flatfield products to flat-field correct any 'proc_' \n",
    "        object images found. Defaults to True.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    **Workflow Details**:\n",
    "    \n",
    "    - **File Classification**:\n",
    "      Invokes `file_classification(dir_path)` to sort `.fits` files by \n",
    "      'OBSTYPE' and 'OBJECT' keywords. Returns a list of directories \n",
    "      (images_to_correct) in which files are placed.\n",
    "\n",
    "    - **Bias Subtraction** (Step 1):\n",
    "      Iterates over each directory in `images_to_correct`. For each FITS file:\n",
    "        - Loads its header to check `NROIS`.\n",
    "        - If `NROIS == 0`, applies a single-sample bias correction (serial overscan, \n",
    "          `apply_bias_correction(..., ROI=False, correction_type='S', single_sample=True, ...)`).\n",
    "        - If `NROIS > 0`, applies a full ROI-based bias correction (serial+parallel, \n",
    "          `apply_bias_correction(..., ROI=True, correction_type='SP', single_sample=False, ...)`).\n",
    "        - Produces an output file prepended with `'proc_'`.\n",
    "\n",
    "    - **Combined Data Products** (Step 2):\n",
    "      For each directory in `images_to_correct`:\n",
    "        - If 'milky' is in the directory name, creates a row-normalized combined product \n",
    "          (`combined_norm_milky.fits`) using `create_combined_product(..., norm=True)`.\n",
    "        \n",
    "    - **Flatfield Correction** (Step 3, optional):\n",
    "      If `flat_filed=True`, the function looks for a milky-flatfield combined product \n",
    "      (containing `'milky'` in the directory name and `'combined'` in the file name). \n",
    "      If found:\n",
    "        - Loads it into a `SkipperImageROI` object for processing, then retrieves the \n",
    "          flatfield data as a NumPy array.\n",
    "        - Searches for any `'proc_'` object files and divides them by the flatfield array, \n",
    "          taking care to handle any dimension mismatches by padding with ones as needed.\n",
    "        - Produces an output FITS file labeled `'flat_filed_proc_<filename>'`.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    SystemExit\n",
    "        If a milky-flatfield directory is not found or a combined milky-flatfield product \n",
    "        cannot be located, the function logs a warning and exits, as no flatfield correction\n",
    "        can be performed.\n",
    "    \"\"\"\n",
    "    header_index_info = 0\n",
    "    \n",
    "    # Implement file classification and get image paths\n",
    "    images_to_correct = file_classification(dir_path)\n",
    "    \n",
    "    # Step 1: Apply bias subtraction \n",
    "    for path in images_to_correct:\n",
    "        if os.path.isdir(path):\n",
    "            for file in os.listdir(path):\n",
    "                img_path = os.path.join(path, file)\n",
    "                out_path = os.path.join(path, 'proc_' + file)\n",
    "                img = fits.open(img_path)\n",
    "                 \n",
    "                ROI_num = int(img[header_index_info].header.get(\"NROIS\", \"UNKNOWN\"))\n",
    "                if ROI_num == 0:\n",
    "                    apply_bias_correction(\n",
    "                        img_path,\n",
    "                        out_path,\n",
    "                        ROI=False,\n",
    "                        correction_type='S',\n",
    "                        single_sample=True,\n",
    "                        gain_correction=True\n",
    "                    )\n",
    "                \n",
    "                elif ROI_num > 0:\n",
    "                    apply_bias_correction(\n",
    "                        img_path,\n",
    "                        out_path,\n",
    "                        ROI=True,\n",
    "                        correction_type='SP',\n",
    "                        single_sample=False,\n",
    "                        gain_correction=True\n",
    "                    )\n",
    "                else:\n",
    "                    log.warning(str(img_path) + \" Unknown number of regions. Proceeding to next image.\")\n",
    "                    continue   \n",
    "        else:\n",
    "            log.warning(str(path) + \" is not a directory. Proceeding...\")\n",
    "            continue \n",
    "\n",
    "    # Step 2: Create 'combined' data products for milky flatfields and bias \n",
    "    for path in images_to_correct:\n",
    "        if 'milky' in path.lower():\n",
    "            fname = 'combined_norm_' + path.split('/')[-1].lower() + '.fits'\n",
    "            out_file_path = os.path.join(path, fname)\n",
    "            create_combined_product(path, out_file_path, norm=True)\n",
    "        \n",
    "        elif 'bias' in path.lower():\n",
    "            fname = 'combined_' + path.split('/')[-1].lower() + '.fits'\n",
    "            out_file_path = os.path.join(path, fname)\n",
    "            create_combined_product(path, out_file_path, norm=False)\n",
    "     \n",
    "    # Step 3: Apply flatfield correction if requested\n",
    "    if flat_filed:\n",
    "        milky_found = False\n",
    "        combined_flat_path = None\n",
    "        \n",
    "        for path in images_to_correct:\n",
    "            if 'milky' in path.lower():\n",
    "                milky_found = True\n",
    "                for file in os.listdir(path):\n",
    "                    if 'combined' in file.lower():\n",
    "                        combined_flat_path = os.path.join(path, file)\n",
    "                        flat_field = SkipperImageROI(\n",
    "                            filename=combined_flat_path,\n",
    "                            overscan_correction_type='none',\n",
    "                            manual_input_slices=False,\n",
    "                            correction_method=\"CUBIC_SPLINE\",\n",
    "                            ROI=False,\n",
    "                            calibration_single_sample=True,\n",
    "                            gain_correction=False\n",
    "                        )\n",
    "                        flat_field.processImage()\n",
    "                        flat_field = flat_field.get_full_image()\n",
    "                break  \n",
    "\n",
    "        if not milky_found:\n",
    "            log.warning(\"Milky-flatfields directory not found: Possibly 'Milky' is missing in the header.\")\n",
    "            log.warning(\"Flatfield correction will not be applied.\")\n",
    "            sys.exit(0)\n",
    "        \n",
    "        if combined_flat_path is None:\n",
    "            log.warning(\"Combined flat-field product not found.\")\n",
    "            log.warning(\"Flatfield correction will not be applied.\")\n",
    "            sys.exit(0)\n",
    "\n",
    "        # Apply the flatfield to object images\n",
    "        for path in images_to_correct:\n",
    "            if 'object' in path.lower():\n",
    "                for file in os.listdir(path):\n",
    "                    if 'proc' in file.lower():\n",
    "                        to_correct_path = os.path.join(path, file)\n",
    "                        img = fits.open(to_correct_path)\n",
    "                        ROI_num = int(img[header_index_info].header.get(\"NROIS\", \"UNKNOWN\"))\n",
    "\n",
    "                        if ROI_num == 0:\n",
    "                            object_img = SkipperImageROI(\n",
    "                                filename=to_correct_path,\n",
    "                                overscan_correction_type='none',\n",
    "                                manual_input_slices=False,\n",
    "                                correction_method=\"CUBIC_SPLINE\",\n",
    "                                ROI=False,\n",
    "                                calibration_single_sample=True,\n",
    "                                gain_correction=False\n",
    "                            )\n",
    "                            object_img.processImage()\n",
    "                            img_data = object_img.get_full_image()\n",
    "\n",
    "                        elif ROI_num > 0:\n",
    "                            object_img = SkipperImageROI(\n",
    "                                filename=to_correct_path,\n",
    "                                overscan_correction_type='none',\n",
    "                                manual_input_slices=False,\n",
    "                                correction_method=\"CUBIC_SPLINE\",\n",
    "                                ROI=False,\n",
    "                                calibration_single_sample=True,\n",
    "                                gain_correction=False\n",
    "                            )\n",
    "                            object_img.processImage()\n",
    "                            img_data = object_img.get_full_image()\n",
    "\n",
    "                        amp_object, row_object, col_object = img_data.shape\n",
    "                        amp_flat, row_flat, col_flat = flat_field.shape\n",
    "\n",
    "                        new_rows = max(row_object, row_flat)\n",
    "                        new_cols = max(col_object, col_flat)\n",
    "                        new_shape = (amp_object, new_rows, new_cols)\n",
    "\n",
    "                        new_image = np.ones(new_shape)\n",
    "                        new_combined_flat_field = np.ones(new_shape)\n",
    "\n",
    "                        new_image[:, :row_object, :col_object] = img_data\n",
    "                        new_combined_flat_field[:, :row_flat, :col_flat] = flat_field\n",
    "\n",
    "                        object_flat_fielded = new_image / new_combined_flat_field\n",
    "                        object_img.set_full_image(object_flat_fielded)\n",
    "\n",
    "                        fname = 'flat_filed_' + file\n",
    "                        out_file_path = os.path.join(path, fname)\n",
    "                        object_img.save(out_file_path, injected=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set the directory path containing the images to be processed\n",
    "    data_path = \"/data/des81.b/data/emarrufo/SIFS_data/SIFS_DATA/20240722_TEST/20240722_test\"\n",
    "\n",
    "    # Call the image_reduction function\n",
    "    image_reduction(data_path, flat_filed=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
